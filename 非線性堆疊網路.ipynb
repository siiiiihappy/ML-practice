{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**使用 Model Functional API 建立各種非線性堆疊網路**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "env: KERAS_BACKEND=tensorflow\n"
     ]
    }
   ],
   "source": [
    "%env KERAS_BACKEND=tensorflow #指定Keras的後端是tensorflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Keras functions\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "# Keras dataset\n",
    "from keras.datasets import mnist\n",
    "\n",
    "# Keras utilis function\n",
    "from keras.utils import np_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = x_train.reshape(60000, 784)\n",
    "x_test = x_test.reshape(10000, 784)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60000, 784) (10000, 784)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape, x_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train = np_utils.to_categorical(y_train, 10) #one-hot encoding\n",
    "y_test = np_utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**1. Model Functional API**\n",
    "\n",
    "使用 Sequential 便足以建構大多數的神經網路，那是因為我們接觸的神經網路多為線性堆疊 (linear stack)。\n",
    "\n",
    "除了輸入層需指定 input_dim 外，其餘隱藏層只需宣告，那是因為 Sequential 會認定上一層的輸出這一層的輸入。\n",
    "\n",
    "因此，再建構線性堆疊的神經網路時，Sequential 便足以處理。\n",
    "\n",
    "**Functional API \n",
    "當神經網路模型為非線性的複雜網路結構，如：**\n",
    "\n",
    "- 多重輸出-多重輸入模型 (Multi-input and multi-output models)\n",
    "- 分歧 (branch)\n",
    "- 合併 (merge)\n",
    "- 具重複/循環結構的模型，如: CycleGAN\n",
    "\n",
    "Sequential 便不足以建構這類複雜結構的神經網路，以下介紹 Model Fnuctional API 的使用。\n",
    "\n",
    "**Functional API 的操作流程如下：**\n",
    "\n",
    "- 將層定義成明確的函數\n",
    "- 透過層函數將變數連接\n",
    "- 定義神經網路的輸入與輸出"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "在 Model 的世界中，所有的神經網路層 (fully-connected, convolution, MaxPooling, LSTM, etc) 都被視作函數來操作，因此只需關心函數的輸入和輸出即可。\n",
    "\n",
    "此外，為了讓神經網路的第一層從不需要輸入 input_dim，還需引進下面這個函數來代替 input_dim。 (此寫法亦可用在 Sequential)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Input #把輸入層讀進來"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "手寫辨識模型是一個長得像這樣的函數\n",
    "\n",
    "$$\\hat{f} \\colon \\mathbb{R}^{784} \\to \\mathbb{R}^{10}$$\n",
    "建立一個具有兩個隱藏層的神經網路來學習這個函數，攤開來看的話，如下：\n",
    "\n",
    "$$\\mathbb{R}^{784} \\overset{f_1}{\\to} \\mathbb{R}^{500} \\overset{f_2}{\\to} \\mathbb{R}^{500} \\overset{f_3}{\\to} \\mathbb{R}^{10}$$$$x \\overset{f_1}{\\mapsto} h_1 \\overset{f_2}{\\mapsto} h_2 \\overset{f_3}{\\mapsto} y$$\n",
    "\n",
    "其中，$f_1, f_2, f_3$ 代表的是全連結層所代表的函數，其他變數說明如下：\n",
    "\n",
    "- $x$: 代表的是輸入模型的圖片向量，為 784 維的向量。\n",
    "- $h_1$: $x$ 經過第一層隱藏層運算後得結果，即為 $f_1(x)$，為 500 維的向量。\n",
    "- $h_2$: $h_1$ 經過第二層隱藏層運算後得結果，即為 $f_2(h_1)$，為 500 維的向量。\n",
    "- $y$: $h_2$ 經過最後一層運算後得結果，即為 $f_3(h_2)$，為 10 維的向量，代表的是 $x$ 為哪個數字的機率。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_1 = Dense(500, activation = 'sigmoid')\n",
    "f_2 = Dense(500, activation = 'sigmoid')\n",
    "f_3 = Dense(10, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras.layers.core.Dense object at 0x0000018DAE143048>\n"
     ]
    }
   ],
   "source": [
    "print(f_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = Input(shape=(784,)) #定義層前後關係，第一個變數必定以Input函數定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"input_1:0\", shape=(?, 784), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "print(x) #Tensor張量 / ?是batch size，一般會在訓練時指定 / 為32位的浮點數"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$h_1 = f_1(x), h_2 = f_2(h_1), y = f_3(h_2)$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_1 = f_1(x)\n",
    "h_2 = f_2(h_1)\n",
    "y = f_3(h_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"dense_1/Sigmoid:0\", shape=(?, 500), dtype=float32)\n",
      "Tensor(\"dense_2/Sigmoid:0\", shape=(?, 500), dtype=float32)\n",
      "Tensor(\"dense_3/Softmax:0\", shape=(?, 10), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "#變數 h_1, h_2, y 是以張量 (tensor) 類別來表示\n",
    "print(h_1)\n",
    "print(h_2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, 784)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 500)               392500    \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 500)               250500    \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 10)                5010      \n",
      "=================================================================\n",
      "Total params: 648,010\n",
      "Trainable params: 648,010\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model=Model(x,y) #x=輸入層 y=輸出的張量\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='mse', optimizer=SGD(lr=0.1), metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 6s 92us/step - loss: 0.0836 - accuracy: 0.3166\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 5s 82us/step - loss: 0.0641 - accuracy: 0.6341\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0458 - accuracy: 0.7711\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 5s 85us/step - loss: 0.0332 - accuracy: 0.8437\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.0258 - accuracy: 0.8724\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x18daf8ba948>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x_train, y_train, batch_size=100, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('NN_handwriting_weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/10000 [==============================] - 1s 90us/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.010542385429143906, 0.9348999857902527]"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(x_test,y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**2.建立具分歧及合併結構的神經網路模型**\n",
    "\n",
    "在模型之間增加一個分歧，且這個分歧在模型的輸出會合併，如下圖所示\n",
    "\n",
    "![](branch-and-merge.png)\n",
    "\n",
    "此模型為單一輸入、多重輸出的模型，是分歧模型最容易處理的一種。\n",
    "\n",
    "其中，$f_1, f_2$ 同之前，$f_4:\\mathbb{R}^{500}\\to\\mathbb{R}^{500}$ 的全連接層，但 Activation 改用 ReLu。\n",
    "\n",
    "需注意的是，由於 $f_3$ 的定義域改變，為 $\\mathbb{R}^{500}\\times\\mathbb{R}^{500}\\to\\mathbb{R}^{10}$ 函數，所以需要重新定義。\n",
    "\n",
    "- $x$: 代表的是輸入模型的圖片向量，為 784 維的向量。\n",
    "- $h_1$: $x$ 經過 $f_1$ 隱藏層運算後得結果，即為 $f_1(x)$，為 500 維的向量。\n",
    "- $h_2$: $h_1$ 經過 $f_2$ 隱藏層運算後得結果，即為 $f_2(h_1)$，為 500 維的向量。\n",
    "\n",
    "- $z$: $h_1$ 經過 $f_4$ 運算後得結果，即為 $f_4(h_1)$，為 500 維的向量。\n",
    "\n",
    "- $y$: $h_2$ 和 $z$ 經過新的 $f_3$ 運算後得結果，即為 $f_3(h_2, z)$，為 10 維的向量，代表的是 $x$ 為哪個數字的機率。\n",
    "\n",
    "因為上面已將 $f_4$ 及 $z$ 以外的變數定義好，只需定義 $f_3$, $f_4$ 及 $z$ 即可"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate, add"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "f_4 = Dense(500, activation = 'relu')\n",
    "z = f_4(h_1) #h_1 = f_1(x)\n",
    "\n",
    "#new f_3\n",
    "f_3 = Dense(10, activation = 'softmax')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__call__() takes 2 positional arguments but 3 were given",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-34-65c27de53f54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0my\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf_3\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mh_2\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mz\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;31m#錯誤，不可放兩個tensor進去\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m: __call__() takes 2 positional arguments but 3 were given"
     ]
    }
   ],
   "source": [
    "y = f_3(h_2,z) #錯誤，不可放兩個tensor進去/y = f_3([h_2,z]) list of tensor也不行"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#將多個獨立的層結合成一層\n",
    "u = concatenate([h_2,z])\n",
    "y = f_3(u)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 784)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 500)          392500      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 500)          250500      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_4 (Dense)                 (None, 500)          250500      dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 1000)         0           dense_2[0][0]                    \n",
      "                                                                 dense_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, 10)           10010       concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 903,510\n",
      "Trainable params: 903,510\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = Model(x,y)\n",
    "model.summary() #dense_1 來自 input_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Branch-and-Merge 的注意要點如下：**\n",
    "\n",
    "每一層分別定義成函數\n",
    "- 分歧結構: 透過新的函數來定義新的變數。\n",
    "- 合併結構: 要合併前，將所有要進入的變數都合併起來，才能進行之後的運算。\n",
    "\n",
    "常見應用:\n",
    "\n",
    "- 多重輸入-多重輸出模型。\n",
    "- 當層函數為 $convolution$ 時，這樣的技巧可以實現 U-net 上的重要結構 multi-resolution fusion (多解析度融合，又稱 MRF)。\n",
    "- ResNet 上的重要結構 skip connection (跳躍式傳遞)，亦可透過分歧-合併來實現，只是 ResNet 使用的是 $add$ 而非 concatenate。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
