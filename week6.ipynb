{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "利用keras functional API，\n",
    "\n",
    "設計一個mnist的分類模型，這個模型可以一次訓練十個獨立的全連接層，\n",
    "\n",
    "每一個獨立的全連接層的目標是學習答案的十維向量裡的其中一個element，\n",
    "\n",
    "每個全連接層有十個神經元，且都跟隨一個average layer把它的輸出做平均，\n",
    "\n",
    "最後再把這十個層的輸出連接起來，取softmax之後比較結果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#keras \n",
    "import keras\n",
    "\n",
    "#使編寫的Keras模塊與Theano ( th)和TensorFlow ( tf)兼容\n",
    "import keras.backend as K\n",
    "from keras.models import Model\n",
    "\n",
    "#model.add(Permute((2, 1), input_shape=(10, 64)))\n",
    "# Permute: model.output_shape == (None, 64, 10) ->置換\n",
    "# Conv2DTranspose: Transposed convolution layer (sometimes called Deconvolution). 逆捲機、卷積轉置\n",
    "from keras.layers import Dense, Activation, Flatten, Permute, Conv1D, Conv2D, Add, Conv2DTranspose \n",
    "from keras.optimizers import Adam\n",
    "from keras.layers import Input, Dense, concatenate, Lambda, Conv2D, Reshape, BatchNormalization, Lambda, Activation \n",
    "\n",
    "#回調函數，在每個訓練期之後保存模型，可以使用回調函數來查看訓練模型的內在狀態和統計。\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "#正則化器允許在優化過程中對層的參數或層的激活情況進行懲罰。任何輸入一個權重矩陣、返回一個損失貢獻張量的函數，都可以用作正則化器。\n",
    "from keras.regularizers import l2\n",
    "\n",
    "from keras.activations import softmax\n",
    "from keras.datasets import mnist\n",
    "from keras.utils import plot_model\n",
    "\n",
    "# tensorflow\n",
    "import tensorflow as tf\n",
    "\n",
    "#numpy\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28)\n",
      "60000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# 把mnist load 進來\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "\n",
    "# 把每個像素的值從(0~255)->(0, 1)\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = keras.utils.to_categorical(y_train, 10)\n",
    "y_test = keras.utils.to_categorical(y_test, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[3]\n",
      " [7]]\n",
      "[3 7]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "a = np.array([[1,2],[3,4]])\n",
    "\n",
    "# 按行相加，并且保持其二维特性\n",
    "print(np.sum(a, axis=1, keepdims=True))\n",
    "\n",
    "# 按行相加，不保持其二维特性\n",
    "print(np.sum(a, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定義Average\n",
    "# keepdims非常重要\n",
    "def average_function(inputs):\n",
    "    return K.mean(inputs, axis=-1, keepdims=True)\n",
    "\n",
    "#把定義好的Average用Lambda封裝起來變成layer\n",
    "average_layer = Lambda(average_function)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model \n",
    "model_input = Input(shape=(28, 28))\n",
    "flatten = Flatten()(model_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業開始"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 十個分開的Dense層，每個層裡面有十個神經元，且輸入都來自flatten\n",
    "# activation function -> relu\n",
    "f_1 = Dense(10, activation = 'relu')\n",
    "h_1 = f_1(flatten)\n",
    "f_2 = Dense(10, activation = 'relu')\n",
    "h_2 = f_2(flatten)\n",
    "f_3 = Dense(10, activation = 'relu')\n",
    "h_3 = f_3(flatten)\n",
    "f_4 = Dense(10, activation = 'relu')\n",
    "h_4 = f_4(flatten)\n",
    "f_5 = Dense(10, activation = 'relu')\n",
    "h_5 = f_5(flatten)\n",
    "f_6 = Dense(10, activation = 'relu')\n",
    "h_6 = f_6(flatten)\n",
    "f_7 = Dense(10, activation = 'relu')\n",
    "h_7 = f_7(flatten)\n",
    "f_8 = Dense(10, activation = 'relu')\n",
    "h_8 = f_8(flatten)\n",
    "f_9 = Dense(10, activation = 'relu')\n",
    "h_9 = f_9(flatten)\n",
    "f_10 = Dense(10, activation = 'relu')\n",
    "h_10 = f_10(flatten)\n",
    "\n",
    "h = [h_1,h_2,h_3,h_4,h_5,h_6,h_7,h_8,h_9,h_10]\n",
    "\n",
    "# 每一個Dense層後面都必須再接一個 average_layer，然後把這十個層整理成一個list\n",
    "# x_1 = Dense(10)\n",
    "# avg_1 = averge_layer(x_1)\n",
    "# list.append(...)\n",
    "'''avg_1 = average_layer(h_1) \n",
    "avg_2 = average_layer(h_2)\n",
    "avg_3 = average_layer(h_3)\n",
    "avg_4 = average_layer(h_4)\n",
    "avg_5 = average_layer(h_5)\n",
    "avg_6 = average_layer(h_6)\n",
    "avg_7 = average_layer(h_7)\n",
    "avg_8 = average_layer(h_8)\n",
    "avg_9 = average_layer(h_9)\n",
    "avg_10 = average_layer(h_10)'''\n",
    "average_list = list(map(lambda i: average_layer(i), h))\n",
    "\n",
    "# 請把這十個層用concatenate層連接起來（把上面的average_list放進去並加上其他參數)\n",
    "# 可使用 python 的 list comprehension\n",
    "concatenate_layer = concatenate(average_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 作業結束"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_3 (InputLayer)            (None, 28, 28)       0                                            \n",
      "__________________________________________________________________________________________________\n",
      "flatten_3 (Flatten)             (None, 784)          0           input_3[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dense_61 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_62 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_63 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_64 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_65 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_66 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_67 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_68 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_69 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_70 (Dense)                (None, 10)           7850        flatten_3[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 1)            0           dense_61[0][0]                   \n",
      "                                                                 dense_62[0][0]                   \n",
      "                                                                 dense_63[0][0]                   \n",
      "                                                                 dense_64[0][0]                   \n",
      "                                                                 dense_65[0][0]                   \n",
      "                                                                 dense_66[0][0]                   \n",
      "                                                                 dense_67[0][0]                   \n",
      "                                                                 dense_68[0][0]                   \n",
      "                                                                 dense_69[0][0]                   \n",
      "                                                                 dense_70[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 10)           0           lambda_1[30][0]                  \n",
      "                                                                 lambda_1[31][0]                  \n",
      "                                                                 lambda_1[32][0]                  \n",
      "                                                                 lambda_1[33][0]                  \n",
      "                                                                 lambda_1[34][0]                  \n",
      "                                                                 lambda_1[35][0]                  \n",
      "                                                                 lambda_1[36][0]                  \n",
      "                                                                 lambda_1[37][0]                  \n",
      "                                                                 lambda_1[38][0]                  \n",
      "                                                                 lambda_1[39][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 10)           0           concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 78,500\n",
      "Trainable params: 78,500\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#加一個softmax\n",
    "model_output = Activation(\"softmax\")(concatenate_layer)\n",
    "\n",
    "model = Model(model_input, model_output)\n",
    "\n",
    "\n",
    "# 你的model.summary理論上會長這樣\n",
    "print(model.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\USER\\anaconda3\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py:422: The name tf.global_variables is deprecated. Please use tf.compat.v1.global_variables instead.\n",
      "\n",
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "60000/60000 [==============================] - 7s 112us/step - loss: 0.5111 - accuracy: 0.8745 - val_loss: 0.3010 - val_accuracy: 0.9181\n",
      "Epoch 2/10\n",
      "60000/60000 [==============================] - 5s 87us/step - loss: 0.2861 - accuracy: 0.9206 - val_loss: 0.2535 - val_accuracy: 0.9289\n",
      "Epoch 3/10\n",
      "60000/60000 [==============================] - 5s 84us/step - loss: 0.2491 - accuracy: 0.9308 - val_loss: 0.2337 - val_accuracy: 0.9333\n",
      "Epoch 4/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.2265 - accuracy: 0.9373 - val_loss: 0.2170 - val_accuracy: 0.9368\n",
      "Epoch 5/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.2108 - accuracy: 0.9416 - val_loss: 0.2064 - val_accuracy: 0.9404\n",
      "Epoch 6/10\n",
      "60000/60000 [==============================] - 5s 78us/step - loss: 0.1985 - accuracy: 0.9445 - val_loss: 0.1951 - val_accuracy: 0.9437\n",
      "Epoch 7/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1887 - accuracy: 0.9470 - val_loss: 0.1877 - val_accuracy: 0.9452\n",
      "Epoch 8/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1800 - accuracy: 0.9495 - val_loss: 0.1824 - val_accuracy: 0.9468\n",
      "Epoch 9/10\n",
      "60000/60000 [==============================] - 5s 77us/step - loss: 0.1724 - accuracy: 0.9515 - val_loss: 0.1794 - val_accuracy: 0.9470\n",
      "Epoch 10/10\n",
      "60000/60000 [==============================] - 5s 76us/step - loss: 0.1658 - accuracy: 0.9531 - val_loss: 0.1733 - val_accuracy: 0.9484\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.callbacks.History at 0x1fcb08f00c8>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# compile & fit\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=\"adam\",\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=32,\n",
    "          epochs=10,\n",
    "          verbose=1,\n",
    "          validation_data=(x_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<tf.Tensor 'lambda_1_31/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_32/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_33/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_34/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_35/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_36/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_37/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_38/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_39/Mean:0' shape=(?, 1) dtype=float32>,\n",
       " <tf.Tensor 'lambda_1_40/Mean:0' shape=(?, 1) dtype=float32>]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor 'concatenate_1/concat:0' shape=(?, 10) dtype=float32>"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "concatenate_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
